{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 0 loss 2.2921438217163086\n",
      "epoch 1 batch 100 loss 0.18474571406841278\n",
      "epoch 1 batch 200 loss 0.40350237488746643\n",
      "epoch 1 batch 300 loss 0.19458512961864471\n",
      "epoch 1 batch 400 loss 0.1777907758951187\n",
      "epoch 1 batch 500 loss 0.3286444842815399\n",
      "epoch 2 batch 0 loss 0.0732782632112503\n",
      "epoch 2 batch 100 loss 0.11235550791025162\n",
      "epoch 2 batch 200 loss 0.23901206254959106\n",
      "epoch 2 batch 300 loss 0.1712895631790161\n",
      "epoch 2 batch 400 loss 0.08825799077749252\n",
      "epoch 2 batch 500 loss 0.1685595065355301\n",
      "epoch 3 batch 0 loss 0.08111123740673065\n",
      "epoch 3 batch 100 loss 0.13382571935653687\n",
      "epoch 3 batch 200 loss 0.03789062798023224\n",
      "epoch 3 batch 300 loss 0.04789008945226669\n",
      "epoch 3 batch 400 loss 0.23688797652721405\n",
      "epoch 3 batch 500 loss 0.034689635038375854\n",
      "epoch 4 batch 0 loss 0.08817217499017715\n",
      "epoch 4 batch 100 loss 0.1316395401954651\n",
      "epoch 4 batch 200 loss 0.03181307017803192\n",
      "epoch 4 batch 300 loss 0.054870251566171646\n",
      "epoch 4 batch 400 loss 0.20736698806285858\n",
      "epoch 4 batch 500 loss 0.06565199047327042\n",
      "epoch 5 batch 0 loss 0.048788994550704956\n",
      "epoch 5 batch 100 loss 0.07016319781541824\n",
      "epoch 5 batch 200 loss 0.16232147812843323\n",
      "epoch 5 batch 300 loss 0.12330903857946396\n",
      "epoch 5 batch 400 loss 0.05367747321724892\n",
      "epoch 5 batch 500 loss 0.031670257449150085\n",
      "epoch 6 batch 0 loss 0.021736297756433487\n",
      "epoch 6 batch 100 loss 0.028896424919366837\n",
      "epoch 6 batch 200 loss 0.09723183512687683\n",
      "epoch 6 batch 300 loss 0.05302257463335991\n",
      "epoch 6 batch 400 loss 0.04923972487449646\n",
      "epoch 6 batch 500 loss 0.0937945619225502\n",
      "accuracy 96.67\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "input_size=784 # 28*28 pixels of image flattened to 1D array of 784\n",
    "classes=10 # 10 classes of digits\n",
    "epochs=6\n",
    "batch_size=100\n",
    "\n",
    "training_dataset = datasets.MNIST(root=\"data\",train=True,download=False,transform=ToTensor(),)\n",
    "test_dataset = datasets.MNIST(root=\"data\",train=False,download=False,transform=ToTensor(),)\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# neural network\n",
    "class mnistNN(nn.Module):\n",
    "    def __init__(self,input_size,classes):\n",
    "        super(mnistNN,self).__init__()\n",
    "        self.linear1=nn.Linear(input_size,128)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.linear2=nn.Linear(128,64)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.linear3=nn.Linear(64,classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.linear1(x)\n",
    "        out=self.relu1(out)\n",
    "        out=self.linear2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.linear3(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model=mnistNN(input_size,classes)\n",
    "\n",
    "# loss and optimizer\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx,(data,labels) in enumerate(train_loader):\n",
    "        data=data.reshape(data.shape[0],-1)\n",
    "        \n",
    "        # forward\n",
    "        scores=model(data)\n",
    "        loss_=loss(scores,labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss_.backward()\n",
    "        \n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "        if batch_idx%100==0:\n",
    "            print(f\"epoch {epoch+1} batch {batch_idx} loss {loss_}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for data,labels in test_loader:\n",
    "        data=data.reshape(data.shape[0],-1)\n",
    "        scores=model(data)\n",
    "\n",
    "        _,predictions=torch.max(scores,1)\n",
    "        n_samples+=labels.shape[0]\n",
    "        n_correct+=(predictions==labels).sum().item()\n",
    "    acc=100.0*n_correct/n_samples\n",
    "    print(f\"accuracy {acc}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# Assuming you have a model instance (replace this with your model)\n",
    "model = models.resnet18()\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'mnist_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726766295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "image=read_image(\"image.jpg\")\n",
    "chnl, height, width = image.shape\n",
    "\n",
    "image_seg=[] # list of 28x28 consequal images's tensors\n",
    "for i in range(width//height):\n",
    "    # split image into 28x28 chunks \n",
    "    img_tensor = image[:, :, i*height:(i+1)*height]\n",
    "    image_seg.append(img_tensor)\n",
    "\n",
    "# predicting value from these 28x28 chunks using model of mnist\n",
    "prediction=0\n",
    "for i in image_seg:\n",
    "    i=i.reshape(1,-1) # datatype of i is torch.uint8\n",
    "    i=i.type(torch.FloatTensor) # datatype of i is torch.float32\n",
    "    pred=model(i)\n",
    "    pred_val=torch.argmax(pred)\n",
    "    prediction=prediction*10+pred_val.item()\n",
    "\n",
    "print(prediction)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
